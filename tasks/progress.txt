## Codebase Patterns
- Script env security: Only pass allowlisted vars (PATH, HOME, USER, LANG, LC_ALL, TZ) via _get_script_env()
- Use `Medic.Helpers.logSettings.logSetup()` for logging configuration
- Follow existing module docstring pattern with description, features, and usage example
- Use `@dataclass` for configuration and status objects
- Test pattern: class-based tests with `@patch` decorators for mocking
- Use `pytest.mark.parametrize` for testing multiple inputs
- Import database module as `import Medic.Core.database as db`
- Module constants should be type-annotated: `CONSTANT: Type = value`
- Rate limiting: All endpoints must be rate limited - no bypass prefixes allowed
- Use `_get_endpoint_rate_limit_config()` to get endpoint-specific rate limits
- Environment variable config: Use `int(os.environ.get("VAR_NAME", "default"))` pattern
- **Datetime utilities: Import `from Medic.Core.utils.datetime_helpers import now as get_now, parse_datetime`**
- **When local var shadows import name, alias the import (e.g., `now as get_now`) to avoid `now = now()` conflicts**
- **Playbook package: Import models and db ops from `Medic.Core.playbook` (not playbook_engine)**
- **Test patches: Use `Medic.Core.playbook.db.db` for db operations moved to playbook package, `Medic.Core.playbook_engine.db` for functions remaining in engine**
- **Executor patches: When testing executor functions directly, patch at `Medic.Core.playbook.executors.<executor_name>.<function>` (e.g., `Medic.Core.playbook.executors.webhook.create_step_result`)**
- **Redis rate limiter: Use `REDIS_URL` env var for connection, `REDIS_POOL_SIZE` for pool (default 10), use `is_healthy()` to check connectivity**
- **Redis testing: Use `fakeredis` package for testing Redis-dependent code**
- **Rate limiter factory: Use `MEDIC_RATE_LIMITER_TYPE` env var (redis/memory/auto) for selection, `get_rate_limiter()` returns cached singleton**
- **Dockerfile: Multi-stage build (builder -> runtime), python:3.11-slim-bookworm base, port 8080, gunicorn WSGI server**
- **Docker user: Non-root user `medic` with uid 1000 for Kubernetes compatibility**

---

## 2026-02-04 - US-011 - Linear Issue: SRE-38
- **What was implemented**: Production Dockerfile with multi-arch support (amd64 and arm64)
  - Multi-stage build: builder stage for installing dependencies, runtime stage for minimal app image
  - Base image: `python:3.11-slim-bookworm` (supports both amd64 and arm64 architectures)
  - Only production dependencies from requirements.txt installed (not dev dependencies)
  - Non-root user `medic` with uid 1000 created for Kubernetes security policies
  - Environment variables: `PYTHONUNBUFFERED=1`, `PYTHONDONTWRITEBYTECODE=1`
  - Exposed port 8080 (production standard)
  - HEALTHCHECK instruction: `curl -f http://localhost:8080/health || exit 1`
  - Labels: maintainer, version, description
  - Gunicorn WSGI server with 2 workers and 4 threads for production performance
  - Created `.dockerignore` excluding: .git, tests/, __pycache__, *.pyc, .env, .venv, tasks/, docs/

- **Files changed**:
  - `Dockerfile` (rewrote with multi-stage build and production optimizations)
  - `.dockerignore` (new file for Docker build context optimization)
  - `tasks/prd.json` (updated passes: true)

- **Learnings for future iterations**:
  - Use `python:3.11-slim-bookworm` for multi-arch support (not alpine - has musl issues)
  - Install `libpq5` in runtime stage (not `libpq-dev`) for psycopg2 runtime
  - Copy Python packages from builder with `COPY --from=builder /root/.local /home/medic/.local`
  - Set uid 1000 explicitly for Kubernetes SecurityContext compatibility
  - Use gunicorn instead of Flask dev server for production
  - All Python dependencies (flask, psycopg2-binary, cryptography, etc.) have pre-built wheels for both amd64 and arm64

---

## 2026-02-04 - US-010 - Linear Issue: SRE-37
- **What was implemented**: Rate limiter factory with automatic Redis/InMemory selection
  - Enhanced `get_rate_limiter()` to auto-select between Redis and InMemory based on config
  - Added `_create_rate_limiter()` internal factory with selection logic
  - Added `MEDIC_RATE_LIMITER_TYPE` env var support: 'redis', 'memory', 'auto' (default: 'auto')
  - Auto mode: Tries Redis if `REDIS_URL` set, falls back to InMemory on failure
  - Redis mode: Forces Redis (raises ValueError if `REDIS_URL` not set)
  - Memory mode: Forces InMemory (ignores Redis even if configured)
  - Logs INFO when selecting limiter, WARNING on Redis fallback
  - Type is case-insensitive (MEMORY, Memory, memory all work)
  - Unknown types fall back to InMemory with WARNING log
  - Limiter instance cached as module-level singleton
  - Middleware already uses `check_rate_limit()` which calls factory - no changes needed

- **Files changed**:
  - `Medic/Core/rate_limiter.py` (enhanced get_rate_limiter, added _create_rate_limiter)
  - `tests/unit/test_rate_limiter.py` (added 14 TestRateLimiterFactory tests)
  - `tasks/prd.json` (updated passes: true)

- **Learnings for future iterations**:
  - Use `_create_rate_limiter()` for the actual creation logic, `get_rate_limiter()` for singleton
  - Test Redis fallback by mocking `_create_redis_client()` and `ping()` methods
  - Mock at `Medic.Core.rate_limiter.RedisRateLimiter._create_redis_client` for client creation
  - Use `set_rate_limiter(None)` in test setup/teardown to reset singleton state
  - Type constants (RATE_LIMITER_TYPE_*) make code more maintainable than string literals

---

## 2026-02-04 - US-009 - Linear Issue: SRE-36
- **What was implemented**: Redis-backed distributed rate limiting for multi-replica deployments
  - Replaced `NotImplementedError` with full `RedisRateLimiter` implementation
  - Used Redis sorted sets (ZSET) for sliding window algorithm
  - Each request stored with timestamp as score for efficient window-based counting
  - Used Redis pipeline with MULTI/EXEC for atomic operations
  - Added `_create_redis_client()` for automatic client creation from `REDIS_URL`
  - Added `REDIS_POOL_SIZE` configuration (default: 10)
  - Added `is_healthy()` method to check Redis connectivity
  - Added key expiry (window_seconds + 1) for automatic cleanup
  - Added 20 unit tests using `fakeredis` for Redis mocking

- **Files changed**:
  - `Medic/Core/rate_limiter.py` (implemented RedisRateLimiter class)
  - `Medic/requirements.txt` (added redis>=5.0.0)
  - `requirements-dev.txt` (added fakeredis>=2.21.0, types-redis>=4.6.0)
  - `tests/unit/test_rate_limiter.py` (added 20 RedisRateLimiter tests)
  - `tasks/prd.json` (updated passes: true)

- **Learnings for future iterations**:
  - Redis sorted sets (ZSET) are ideal for sliding window rate limiting
  - Use `zadd()` with timestamp as score, `zremrangebyscore()` to remove old entries
  - Use `zcard()` to count current entries, `zrange()` with `withscores=True` for oldest entry
  - Always set key expiry with `expire()` for automatic cleanup
  - Use `redis.ConnectionPool.from_url()` for connection pooling
  - `fakeredis` package provides in-memory Redis for testing without real Redis server
  - Test `is_healthy()` by mocking `ping()` to raise exceptions

---

## 2026-02-04 - US-008 - Linear Issue: SRE-35
- **What was implemented**: Extracted playbook step executors to separate modules
  - Created `Medic/Core/playbook/executors/` package directory
  - Created `Medic/Core/playbook/executors/__init__.py` with exports for all executors
  - Created `Medic/Core/playbook/executors/webhook.py` with:
    - `execute_webhook_step()`: HTTP request execution with variable/secret substitution
    - `substitute_variables()`: ${VAR_NAME} syntax substitution
    - `substitute_all()`: Combined variable and secret substitution
    - `_build_webhook_context()`: Build execution context for substitutions
  - Created `Medic/Core/playbook/executors/script.py` with:
    - `execute_script_step()`: Pre-registered script execution with resource limits
    - `get_registered_script()`: Fetch script from database
    - `RegisteredScript`: Dataclass for script metadata
    - `_get_script_env()`: Build secure environment (allowlist-based)
    - `_substitute_script_variables()`: Script content substitution
  - Created `Medic/Core/playbook/executors/condition.py` with:
    - `execute_condition_step()`: Condition polling with timeout
    - `check_heartbeat_received()`: Heartbeat condition checker
  - Created `Medic/Core/playbook/executors/wait.py` with:
    - `execute_wait_step()`: Simple duration-based wait
  - Updated `playbook_engine.py` to import from executors and re-export for backwards compatibility
  - Updated 50+ test patches to use correct module paths

- **Files changed**:
  - `Medic/Core/playbook/executors/__init__.py` (new)
  - `Medic/Core/playbook/executors/webhook.py` (new)
  - `Medic/Core/playbook/executors/script.py` (new)
  - `Medic/Core/playbook/executors/condition.py` (new)
  - `Medic/Core/playbook/executors/wait.py` (new)
  - `Medic/Core/playbook_engine.py` (refactored imports, removed executor code)
  - `tests/unit/test_playbook_engine.py` (updated 50+ mock patches)
  - `tasks/prd.json` (updated passes: true)

- **Learnings for future iterations**:
  - When extracting functions to new modules, ALL patches must be updated to new locations
  - Patches must target where functions are IMPORTED/USED, not where they're defined
  - For executor functions, patch at `Medic.Core.playbook.executors.<executor>.<function>`
  - Re-exports with `# noqa: F401` on import line maintains backwards compatibility
  - Testing scripts that use db.query_db requires patching `Medic.Core.playbook.executors.<module>.db`
  - Executor tests that directly call the function need patches at the executor module level
  - Engine tests that use execute_step() may need patches at wait module for WaitStep tests

---

## 2026-02-04 - US-007 - Linear Issue: SRE-34
- **What was implemented**: Created playbook package structure for maintainability
  - Created `Medic/Core/playbook/` package directory
  - Created `Medic/Core/playbook/models.py` with dataclasses:
    - `ExecutionStatus`: Enum for playbook execution states
    - `StepResultStatus`: Enum for step result states
    - `StepResult`: Dataclass for step execution results
    - `PlaybookExecution`: Dataclass for playbook execution instances
    - `StepExecutor`: Type alias for step executor functions
  - Created `Medic/Core/playbook/db.py` with all database operations:
    - Execution: create_execution, get_execution, get_active_executions, etc.
    - Step results: create_step_result, update_step_result, etc.
    - Playbook loading: get_playbook_by_id
  - Created `Medic/Core/playbook/__init__.py` with public API exports
  - Updated `playbook_engine.py` to import from new package
  - Updated test patches to use correct module paths

- **Files changed**:
  - `Medic/Core/playbook/__init__.py` (new)
  - `Medic/Core/playbook/models.py` (new)
  - `Medic/Core/playbook/db.py` (new)
  - `Medic/Core/playbook_engine.py` (refactored imports, removed duplicated code)
  - `tests/unit/test_playbook_engine.py` (updated mock patches)
  - `tasks/prd.json` (updated passes: true)

- **Learnings for future iterations**:
  - When moving database functions to a new module, tests need patches updated to new location
  - Functions in playbook.db module need `@patch('Medic.Core.playbook.db.db')` for db mocking
  - Functions remaining in playbook_engine need `@patch('Medic.Core.playbook_engine.db')` for db mocking
  - TYPE_CHECKING imports help avoid circular imports for type hints
  - Package __init__.py can re-export all public API for convenience imports
  - Keep backwards compatibility by importing and re-exporting from old module location

---

## 2026-02-04 - US-006 - Linear Issue: SRE-33
- **What was implemented**: Extracted shared datetime utilities to single module
  - Created `Medic/Core/utils/__init__.py` (empty package init)
  - Created `Medic/Core/utils/datetime_helpers.py` with:
    - `TIMEZONE: pytz.BaseTzInfo = pytz.timezone('America/Chicago')` constant
    - `now() -> datetime` function for timezone-aware current time
    - `parse_datetime(dt_str: str) -> Optional[datetime]` for multi-format parsing
  - Replaced 6 duplicate `_now()` implementations with centralized `get_now()`
  - Replaced 4 duplicate `_parse_datetime()` implementations with centralized `parse_datetime()`
  - Removed unused `pytz` imports from modules using datetime_helpers

- **Files changed**:
  - `Medic/Core/utils/__init__.py` (new)
  - `Medic/Core/utils/datetime_helpers.py` (new)
  - `Medic/Core/playbook_engine.py` (import datetime_helpers, remove _now/_parse_datetime)
  - `Medic/Core/audit_log.py` (import datetime_helpers, remove _now/_parse_datetime)
  - `Medic/Core/slack_approval.py` (import datetime_helpers, remove _now/_parse_datetime)
  - `Medic/Core/secrets.py` (import datetime_helpers, remove _now)
  - `Medic/Core/circuit_breaker.py` (import datetime_helpers, remove _now)
  - `Medic/Core/job_runs.py` (import datetime_helpers, remove _parse_datetime)
  - `tests/unit/test_circuit_breaker.py` (update mocks for get_now)
  - `tests/unit/test_job_runs.py` (update imports for parse_datetime)
  - `tests/unit/test_playbook_engine.py` (update imports for parse_datetime)
  - `tasks/prd.json` (updated passes: true)

- **Learnings for future iterations**:
  - When importing a function that will be used as `var = func()`, alias the import to avoid shadowing
  - Example: `from module import now as get_now` prevents `now = now()` from failing
  - Mock paths must match the aliased import name (e.g., `@patch('module.get_now')` not `@patch('module.now')`)
  - pytz.BaseTzInfo is the correct type hint for timezone objects
  - Empty `__init__.py` creates a Python package; no content needed for basic package structure
  - Centralized utilities reduce code duplication but require updating all tests that mock the old functions

---

## 2026-02-04 - US-005 - Linear Issue: SRE-32
- **What was implemented**: Added rate limiting to ALL endpoints (no bypasses)
  - Removed `/metrics` and `/docs` from `RATE_LIMIT_BYPASS_PREFIXES`
  - Replaced bypass mechanism with endpoint-specific rate limits
  - Added `RATE_LIMIT_HEALTH_REQUESTS` config (default: 1000 req/min) for /health
  - Added `RATE_LIMIT_METRICS_REQUESTS` config (default: 100 req/min) for /metrics
  - Added `RATE_LIMIT_DOCS_REQUESTS` config (default: 60 req/min) for /docs
  - Created `_get_endpoint_rate_limit_config()` to return appropriate config
  - Updated `_determine_endpoint_type()` to detect health, metrics, docs types
  - Removed `_should_bypass_rate_limit()` function entirely
  - All 47 unit tests pass verifying no endpoints bypass rate limiting

- **Files changed**:
  - `Medic/Core/rate_limit_middleware.py` (refactored rate limit bypass to endpoint-specific limits)
  - `tests/unit/test_rate_limit_middleware.py` (updated and added 47 tests)
  - `tasks/prd.json` (updated passes: true)

- **Learnings for future iterations**:
  - Security best practice: Never bypass rate limiting - use endpoint-specific limits instead
  - When changing bypass behavior, integration tests need custom configs explicitly passed
  - Endpoint type constants (`ENDPOINT_TYPE_*`) help maintain consistency across functions
  - Rate limit middleware applies endpoint-specific config when no custom config provided
  - Tests for "no bypass" should verify the check function IS called (not assert_not_called)

---

## 2026-02-03 22:00 - US-001 - Linear Issue: SRE-28
- **What was implemented**: URL validator module for SSRF prevention
  - Created `Medic/Core/url_validator.py` with:
    - `InvalidURLError` exception class
    - `validate_url(url: str, skip_dns_check: bool = False) -> bool` function
    - `is_private_ip(ip: str) -> bool` helper function
    - `is_safe_url(url: str) -> bool` convenience wrapper
    - `get_allowed_hosts() -> Optional[Set[str]]` for env var support
    - `resolve_hostname(hostname: str) -> List[str]` for DNS rebinding prevention
  - Blocks private IP ranges: 127.0.0.0/8, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16, 169.254.0.0/16, 0.0.0.0/8
  - Blocks IPv6 private ranges: ::1/128, fc00::/7, fe80::/10, ::/128
  - Blocks localhost, 0.0.0.0, cloud metadata (169.254.169.254)
  - Only allows http/https schemes
  - Performs DNS resolution to catch DNS rebinding attacks
  - Supports `MEDIC_ALLOWED_WEBHOOK_HOSTS` env var for explicit allowlist
  - Error messages are generic to prevent information leakage

- **Files changed**:
  - `Medic/Core/url_validator.py` (new)
  - `tests/unit/test_url_validator.py` (new, 128 tests)
  - `tasks/prd.json` (updated passes: true)

- **Learnings for future iterations**:
  - The codebase uses `logger.log(level=30, msg="...")` pattern instead of `logger.warning()`
  - Type annotations are important - mypy is strict about List types needing explicit annotation
  - IPv6 networks need separate handling from IPv4 networks in type annotations
  - Tests should use `skip_dns_check=True` when testing URL validation without network calls
  - `socket.getaddrinfo` returns tuples where index [4][0] is the IP address
  - Use `patch.dict('os.environ', {...})` for testing environment variables

---

## 2026-02-04 00:30 - US-003 - Linear Issue: SRE-30
- **What was implemented**: Fixed timing attack vulnerability in API key verification
  - Modified `_get_api_key_from_db()` in `auth_middleware.py` to prevent timing attacks
  - Instead of returning immediately when a match is found, the function now:
    - Stores matched key in a variable
    - Continues iterating through ALL keys
    - Returns matched key only after complete iteration
  - Added detailed code comment explaining the timing attack mitigation
  - Added 4 unit tests verifying all keys are checked regardless of match position

- **Files changed**:
  - `Medic/Core/auth_middleware.py` (modified _get_api_key_from_db function)
  - `tests/unit/test_auth_middleware.py` (new TestGetApiKeyFromDbTimingAttack class with 4 tests)
  - `tasks/prd.json` (updated passes: true)

- **Learnings for future iterations**:
  - Timing attacks can be used to enumerate API keys by measuring response times
  - Always iterate through all items in security-sensitive comparisons to maintain constant time
  - Use `mock.side_effect = [True, False, False, ...]` to simulate different match positions in tests
  - Verify timing attack mitigation by asserting `mock.call_count == total_items`
  - Pre-existing lint errors (E501 line-too-long) are in the codebase - flake8 config may need updating

---

## 2026-02-03 23:15 - US-002 - Linear Issue: SRE-29
- **What was implemented**: Integrated URL validator into webhook execution
  - Added `from Medic.Core.url_validator import InvalidURLError, validate_url` to `playbook_engine.py`
  - Call `validate_url(url)` in `execute_webhook_step()` after variable substitution, before HTTP request
  - On `InvalidURLError`, return `StepResult` with `FAILED` status and "Invalid webhook URL" message
  - Added `from Medic.Core.url_validator import InvalidURLError, validate_url` to `webhook_delivery.py`
  - Call `validate_url(url)` in `_send_request()` before HTTP request
  - Log validation failures at WARNING level using `logger.warning()`
  - Added 11 integration tests (5 in test_playbook_engine.py, 6 in test_webhook_delivery.py)

- **Files changed**:
  - `Medic/Core/playbook_engine.py` (import + validation in execute_webhook_step)
  - `Medic/Core/webhook_delivery.py` (import + validation in _send_request)
  - `tests/unit/test_playbook_engine.py` (new TestExecuteWebhookStepSSRFPrevention class)
  - `tests/unit/test_webhook_delivery.py` (new TestWebhookDeliveryServiceSSRFPrevention class)
  - `tasks/prd.json` (updated passes: true)

- **Learnings for future iterations**:
  - URL validation should happen AFTER variable substitution so ${secrets.XXX} and ${VAR} are resolved first
  - Use `@patch('Medic.Core.module.validate_url')` to mock URL validation in tests
  - The playbook_engine uses `StepResult` dataclass for return values with specific status codes
  - webhook_delivery uses `DeliveryResult` dataclass with `success` and `error_message` fields
  - When validation fails, HTTP client should NOT be called - verify with `mock_client.assert_not_called()`

---

## 2026-02-04 01:45 - US-004 - Linear Issue: SRE-31
- **What was implemented**: Fixed script execution environment variable leak
  - Created `ALLOWED_SCRIPT_ENV_VARS` constant with safe vars: PATH, HOME, USER, LANG, LC_ALL, TZ
  - Created `_get_script_env(execution)` function to build safe environment dictionary
  - Modified `execute_script_step()` to use `_get_script_env()` instead of `**dict(os.environ)`
  - Added support for `MEDIC_ADDITIONAL_SCRIPT_ENV_VARS` env var to extend allowlist
  - Added 8 unit tests in `TestGetScriptEnvSecurity` class verifying:
    - MEDIC_SECRETS_KEY is NOT passed to scripts
    - DATABASE_URL is NOT passed to scripts
    - AWS credentials are NOT passed to scripts
    - Only allowlisted variables are passed
    - MEDIC context vars (MEDIC_EXECUTION_ID, MEDIC_PLAYBOOK_ID, MEDIC_SERVICE_ID) always present
    - MEDIC_ADDITIONAL_SCRIPT_ENV_VARS extends allowlist
    - Empty/whitespace handling for additional vars

- **Files changed**:
  - `Medic/Core/playbook_engine.py` (added ALLOWED_SCRIPT_ENV_VARS, _get_script_env, modified execute_script_step)
  - `tests/unit/test_playbook_engine.py` (new TestGetScriptEnvSecurity class with 8 tests)
  - `tasks/prd.json` (updated passes: true)

- **Learnings for future iterations**:
  - Environment variables passed to subprocess.run() via `env=` parameter replace the entire environment
  - Using `**dict(os.environ)` is a security antipattern - it leaks all secrets to subprocesses
  - Use `patch.dict('os.environ', {...})` for testing environment variables
  - The forward reference `"PlaybookExecution"` in type hints requires quotes for circular import prevention
  - Flake8 enforces 79 char line limit - keep comments under that limit

---
