{
  "project": "Medic EKS Production",
  "branchName": "feature/medic-eks-production",
  "description": "Deploy Medic to Amazon EKS with production-grade security, observability, and reliability. Addresses critical security vulnerabilities from PR #2 review, implements Helm chart deployed via Terraform helm_release, OpenTelemetry instrumentation for Grafana/Loki/Tempo correlation, KEDA for autoscaling, and Karpenter-aware scheduling.",
  "linearProject": "Medic v2",
  "gitWorkflow": {
    "baseBranch": "main",
    "pullBeforeStart": true,
    "commitMessageFormat": "feat: [LINEAR_TICKET_ID] - Description",
    "coAuthor": "Claude Opus 4.5 <noreply@anthropic.com>"
  },
  "userStories": [
    {
      "id": "US-001",
      "linearTicket": "SRE-28",
      "title": "Create URL validator module for SSRF prevention",
      "description": "As a security engineer, I need a URL validation module to prevent Server-Side Request Forgery attacks against internal services.",
      "acceptanceCriteria": [
        "Create `Medic/Core/url_validator.py` module",
        "Implement `validate_url(url: str) -> bool` function",
        "Implement `is_private_ip(ip: str) -> bool` helper function",
        "Block private IP ranges: 127.0.0.0/8, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16, 169.254.0.0/16",
        "Block localhost, 0.0.0.0, and cloud metadata endpoint (169.254.169.254)",
        "Only allow http/https schemes",
        "Perform DNS resolution to catch DNS rebinding attacks",
        "Add `MEDIC_ALLOWED_WEBHOOK_HOSTS` env var support for explicit allowlist",
        "Raise `InvalidURLError` with safe message (no internal details)",
        "Add 20+ unit tests covering all blocked ranges and edge cases",
        "Typecheck/lint passes"
      ],
      "priority": 1,
      "passes": true,
      "notes": "Critical security fix - blocks SSRF attacks"
    },
    {
      "id": "US-002",
      "linearTicket": "SRE-29",
      "title": "Integrate URL validator into webhook execution",
      "description": "As a security engineer, I need webhook steps and webhook delivery to validate URLs before making requests.",
      "acceptanceCriteria": [
        "Import url_validator in `playbook_engine.py`",
        "Call `validate_url()` in `execute_webhook_step()` before making request",
        "Return 400 error with 'Invalid webhook URL' message on validation failure",
        "Import url_validator in `webhook_delivery.py`",
        "Call `validate_url()` in `_send_request()` before making request",
        "Log validation failures at WARNING level",
        "Add 5+ integration tests verifying blocked URLs are rejected",
        "Typecheck/lint passes"
      ],
      "priority": 2,
      "passes": true,
      "notes": "Depends on US-001 (SRE-28)",
      "blockedBy": ["SRE-28"]
    },
    {
      "id": "US-003",
      "linearTicket": "SRE-30",
      "title": "Fix timing attack in API key verification",
      "description": "As a security engineer, I need API key verification to be constant-time to prevent timing-based key enumeration attacks.",
      "acceptanceCriteria": [
        "Modify `_get_api_key_from_db()` in `auth_middleware.py`",
        "Store matched key in variable instead of early return",
        "Continue iterating through ALL keys even after match found",
        "Return matched key only after complete iteration",
        "Add code comment explaining timing attack mitigation",
        "Add unit test verifying all keys are checked when match found early",
        "Typecheck/lint passes"
      ],
      "priority": 3,
      "passes": true,
      "notes": "Critical security fix - prevents timing attacks"
    },
    {
      "id": "US-004",
      "linearTicket": "SRE-31",
      "title": "Fix script execution environment variable leak",
      "description": "As a security engineer, I need script execution to use an allowlist of environment variables to prevent secrets from leaking.",
      "acceptanceCriteria": [
        "Create `ALLOWED_SCRIPT_ENV_VARS` constant in `playbook_engine.py`: ['PATH', 'HOME', 'USER', 'LANG', 'LC_ALL', 'TZ']",
        "Modify `execute_script_step()` to filter `os.environ` using allowlist",
        "Only pass allowlisted vars plus explicit `MEDIC_EXECUTION_ID`, `MEDIC_PLAYBOOK_ID`, `MEDIC_SERVICE_ID`",
        "Add `MEDIC_ADDITIONAL_SCRIPT_ENV_VARS` env var for extending allowlist",
        "Add code comment documenting security model",
        "Add unit test verifying MEDIC_SECRETS_KEY is NOT passed to scripts",
        "Add unit test verifying DATABASE_URL is NOT passed to scripts",
        "Typecheck/lint passes"
      ],
      "priority": 4,
      "passes": true,
      "notes": "Critical security fix - prevents secret leakage"
    },
    {
      "id": "US-005",
      "linearTicket": "SRE-32",
      "title": "Add rate limiting to all endpoints",
      "description": "As a security engineer, I need all endpoints rate limited to prevent abuse and DoS attacks.",
      "acceptanceCriteria": [
        "Remove `/metrics` from `RATE_LIMIT_BYPASS_PREFIXES` in `rate_limit_middleware.py`",
        "Remove `/docs` from `RATE_LIMIT_BYPASS_PREFIXES`",
        "Add `RATE_LIMIT_HEALTH_REQUESTS` config (default: 1000 req/min) for health endpoints",
        "Add `RATE_LIMIT_METRICS_REQUESTS` config (default: 100 req/min) for /metrics",
        "Add `RATE_LIMIT_DOCS_REQUESTS` config (default: 60 req/min) for /docs",
        "Implement endpoint-specific rate limits in middleware",
        "Update unit tests to verify no endpoints bypass rate limiting",
        "Typecheck/lint passes"
      ],
      "priority": 5,
      "passes": true,
      "notes": "Security hardening"
    },
    {
      "id": "US-006",
      "linearTicket": "SRE-33",
      "title": "Extract shared datetime utilities",
      "description": "As a developer, I need a single source of truth for datetime helpers to eliminate code duplication.",
      "acceptanceCriteria": [
        "Create `Medic/Core/utils/__init__.py` (empty file)",
        "Create `Medic/Core/utils/datetime_helpers.py`",
        "Add `TIMEZONE = pytz.timezone('America/Chicago')` constant",
        "Add `now() -> datetime` function returning timezone-aware datetime",
        "Add `parse_datetime(dt_str: str) -> Optional[datetime]` function",
        "Replace `_now()` in `playbook_engine.py` with import from datetime_helpers",
        "Replace `_now()` in `audit_log.py` with import from datetime_helpers",
        "Replace `_now()` in `slack_approval.py` with import from datetime_helpers",
        "Replace `_now()` in `secrets.py` with import from datetime_helpers",
        "Replace `_now()` in `circuit_breaker.py` with import from datetime_helpers",
        "Replace `_now()` in `job_runs.py` with import from datetime_helpers",
        "Delete all duplicate `_now()` implementations",
        "All existing tests pass",
        "Typecheck/lint passes"
      ],
      "priority": 6,
      "passes": true,
      "notes": "Code quality improvement"
    },
    {
      "id": "US-007",
      "linearTicket": "SRE-34",
      "title": "Create playbook package structure",
      "description": "As a developer, I need the playbook module restructured into a package for maintainability.",
      "acceptanceCriteria": [
        "Create `Medic/Core/playbook/` directory",
        "Create `Medic/Core/playbook/__init__.py` with public API exports",
        "Create `Medic/Core/playbook/models.py` with dataclasses: PlaybookExecution, StepResult, ExecutionStatus, StepResultStatus",
        "Create `Medic/Core/playbook/db.py` with all database operations (create_execution, update_execution, etc.)",
        "Move relevant code from `playbook_engine.py` to new modules",
        "Update imports in `playbook_engine.py` to use new modules",
        "All existing tests pass",
        "Typecheck/lint passes"
      ],
      "priority": 7,
      "passes": true,
      "notes": "Part 1 of playbook_engine.py refactor"
    },
    {
      "id": "US-008",
      "linearTicket": "SRE-35",
      "title": "Extract playbook step executors",
      "description": "As a developer, I need step executors in separate modules for maintainability.",
      "acceptanceCriteria": [
        "Create `Medic/Core/playbook/executors/__init__.py`",
        "Create `Medic/Core/playbook/executors/webhook.py` with execute_webhook_step",
        "Create `Medic/Core/playbook/executors/script.py` with execute_script_step",
        "Create `Medic/Core/playbook/executors/condition.py` with execute_condition_step",
        "Create `Medic/Core/playbook/executors/wait.py` with execute_wait_step",
        "Move relevant code from `playbook_engine.py` to executor modules",
        "Update imports in `playbook_engine.py` to use new executors",
        "Keep `playbook_engine.py` as facade re-exporting for backwards compatibility",
        "All 108 existing playbook_engine tests pass",
        "Typecheck/lint passes"
      ],
      "priority": 8,
      "passes": true,
      "notes": "Part 2 of playbook_engine.py refactor. Depends on US-007.",
      "blockedBy": ["SRE-34"]
    },
    {
      "id": "US-009",
      "linearTicket": "SRE-36",
      "title": "Implement RedisRateLimiter class",
      "description": "As an operator, I need distributed rate limiting via Redis so limits work correctly across multiple API replicas.",
      "acceptanceCriteria": [
        "Replace NotImplementedError in `RedisRateLimiter` class in `rate_limiter.py`",
        "Add `redis` package to requirements.txt",
        "Implement `check_rate_limit()` using Redis MULTI/EXEC for atomic operations",
        "Implement sliding window algorithm matching InMemoryRateLimiter behavior",
        "Add `REDIS_URL` environment variable support for connection string",
        "Add connection pooling with `REDIS_POOL_SIZE` config (default: 10)",
        "Implement `is_healthy()` method to check Redis connectivity",
        "Add 15+ unit tests with Redis mocking (use fakeredis or unittest.mock)",
        "Typecheck/lint passes"
      ],
      "priority": 9,
      "passes": true,
      "notes": "Infrastructure for distributed rate limiting"
    },
    {
      "id": "US-010",
      "linearTicket": "SRE-37",
      "title": "Add rate limiter factory with auto-selection",
      "description": "As an operator, I need the rate limiter to automatically select Redis or in-memory based on configuration.",
      "acceptanceCriteria": [
        "Create `get_rate_limiter()` factory function in `rate_limiter.py`",
        "If `REDIS_URL` is set and `MEDIC_RATE_LIMITER_TYPE` is 'auto' or 'redis', return RedisRateLimiter",
        "If RedisRateLimiter fails to connect, fall back to InMemoryRateLimiter with WARNING log",
        "If `REDIS_URL` is not set, return InMemoryRateLimiter with INFO log",
        "Add `MEDIC_RATE_LIMITER_TYPE` env var: 'redis', 'memory', 'auto' (default: 'auto')",
        "Cache limiter instance as module-level singleton",
        "Update `rate_limit_middleware.py` to use `get_rate_limiter()` factory",
        "Add unit tests for factory selection logic",
        "Typecheck/lint passes"
      ],
      "priority": 10,
      "passes": false,
      "notes": "Depends on US-009",
      "blockedBy": ["SRE-36"]
    },
    {
      "id": "US-011",
      "linearTicket": "SRE-38",
      "title": "Create production Dockerfile with multi-arch support",
      "description": "As a DevOps engineer, I need a production-optimized Docker image supporting both amd64 and arm64 architectures.",
      "acceptanceCriteria": [
        "Create `Dockerfile` in repository root",
        "Use multi-stage build: builder stage for dependencies, runtime stage for app",
        "Base image: `python:3.11-slim-bookworm` (supports both amd64 and arm64)",
        "Install only production dependencies from requirements.txt (not dev)",
        "Create non-root user with uid 1000",
        "Set `PYTHONUNBUFFERED=1` and `PYTHONDONTWRITEBYTECODE=1`",
        "Expose port 8080",
        "Add HEALTHCHECK instruction: `curl -f http://localhost:8080/health || exit 1`",
        "Add labels: maintainer, version, description",
        "Create `.dockerignore` excluding: .git, tests/, __pycache__, *.pyc, .env, .venv",
        "Ensure no architecture-specific dependencies (pure Python or cross-platform wheels)",
        "Verify image builds for amd64: `docker build --platform linux/amd64 .`",
        "Verify image builds for arm64: `docker build --platform linux/arm64 .`"
      ],
      "priority": 11,
      "passes": false,
      "notes": "Container setup - must support both amd64 (x86) and arm64 (Graviton/M1)"
    },
    {
      "id": "US-012",
      "linearTicket": "SRE-39",
      "title": "Create Docker Compose for local development",
      "description": "As a developer, I need Docker Compose to run Medic with all dependencies locally.",
      "acceptanceCriteria": [
        "Create `docker-compose.yml` in repository root",
        "Define service: medic-api (build from Dockerfile, port 8080)",
        "Define service: medic-worker (build from Dockerfile, different command)",
        "Define service: postgres (image: postgres:15, persistent volume, healthcheck)",
        "Define service: redis (image: redis:7, persistent volume, healthcheck)",
        "Configure medic-api depends_on postgres and redis with condition: service_healthy",
        "Create `.env.example` with all required environment variables (placeholder values)",
        "Environment variables loaded from .env file",
        "Verify `docker-compose config` validates successfully"
      ],
      "priority": 12,
      "passes": false,
      "notes": "Local development setup"
    },
    {
      "id": "US-013",
      "linearTicket": "SRE-40",
      "title": "Create Helm chart structure for Medic",
      "description": "As a DevOps engineer, I need a Helm chart for deploying Medic to Kubernetes.",
      "acceptanceCriteria": [
        "Create `helm/medic/` directory in repository root",
        "Create `helm/medic/Chart.yaml` with name, version, appVersion, description",
        "Create `helm/medic/values.yaml` with default configuration values",
        "Create `helm/medic/templates/_helpers.tpl` with common template helpers",
        "Create `helm/medic/templates/namespace.yaml` (optional, controlled by value)",
        "Create `helm/medic/templates/NOTES.txt` with post-install instructions",
        "Values should include: image.repository, image.tag, replicaCount, resources, env, secrets",
        "Verify `helm lint helm/medic` passes",
        "Verify `helm template medic helm/medic` renders valid YAML"
      ],
      "priority": 13,
      "passes": false,
      "notes": "Helm chart foundation - will be deployed via Terraform helm_release"
    },
    {
      "id": "US-014",
      "linearTicket": "SRE-41",
      "title": "Create API Deployment Helm template",
      "description": "As a DevOps engineer, I need a Helm template for the Medic API Deployment.",
      "acceptanceCriteria": [
        "Create `helm/medic/templates/api-deployment.yaml`",
        "Deployment name: {{ include \"medic.fullname\" . }}-api",
        "Replicas from values: {{ .Values.api.replicaCount }}",
        "Image: {{ .Values.image.repository }}:{{ .Values.image.tag }}",
        "Resources from values: {{ .Values.api.resources }}",
        "Liveness probe: /health/live, configurable delays",
        "Readiness probe: /health/ready, configurable delays",
        "Security context: runAsNonRoot, runAsUser, readOnlyRootFilesystem",
        "Pod anti-affinity for spreading across nodes",
        "Topology spread constraints for Karpenter multi-AZ distribution",
        "Environment variables from values and secrets",
        "Add values.yaml defaults for api section",
        "Verify `helm template` renders valid deployment"
      ],
      "priority": 14,
      "passes": false,
      "notes": "Core API deployment template with Karpenter-aware scheduling"
    },
    {
      "id": "US-015",
      "linearTicket": "SRE-42",
      "title": "Create Worker Deployment Helm template",
      "description": "As a DevOps engineer, I need a Helm template for the Medic Worker Deployment.",
      "acceptanceCriteria": [
        "Create `helm/medic/templates/worker-deployment.yaml`",
        "Deployment name: {{ include \"medic.fullname\" . }}-worker",
        "Replicas: {{ .Values.worker.replicaCount }} (default: 1)",
        "Container command: ['python', '-m', 'Medic.Worker.monitor']",
        "Resources from values: {{ .Values.worker.resources }}",
        "Liveness probe configurable",
        "Security context matching API deployment",
        "Environment variables shared with API",
        "Add values.yaml defaults for worker section",
        "Verify `helm template` renders valid deployment"
      ],
      "priority": 15,
      "passes": false,
      "notes": "Worker deployment template"
    },
    {
      "id": "US-016",
      "linearTicket": "SRE-43",
      "title": "Create Service and Ingress Helm templates",
      "description": "As a DevOps engineer, I need Helm templates for Service and ALB Ingress.",
      "acceptanceCriteria": [
        "Create `helm/medic/templates/api-service.yaml` - ClusterIP service",
        "Service port configurable via values",
        "Create `helm/medic/templates/ingress.yaml` with conditional creation",
        "Ingress enabled via {{ .Values.ingress.enabled }}",
        "ALB annotations configurable via values",
        "Host configurable: {{ .Values.ingress.host }}",
        "TLS configurable: {{ .Values.ingress.tls }}",
        "Certificate ARN configurable for ALB",
        "Add values.yaml defaults for ingress section",
        "Verify `helm template` renders valid service and ingress"
      ],
      "priority": 16,
      "passes": false,
      "notes": "External access via ALB"
    },
    {
      "id": "US-017",
      "linearTicket": "SRE-44",
      "title": "Create ConfigMap, Secret, and ServiceAccount Helm templates",
      "description": "As a DevOps engineer, I need Helm templates for configuration and secrets management.",
      "acceptanceCriteria": [
        "Create `helm/medic/templates/configmap.yaml` for non-sensitive config",
        "ConfigMap values from {{ .Values.config }} map",
        "Create `helm/medic/templates/secret.yaml` for sensitive values (optional, for non-ESO use)",
        "Secret creation controlled by {{ .Values.secret.create }}",
        "Create `helm/medic/templates/external-secret.yaml` for ESO integration",
        "ExternalSecret creation controlled by {{ .Values.externalSecret.enabled }}",
        "ExternalSecret secretStoreRef configurable",
        "Create `helm/medic/templates/serviceaccount.yaml`",
        "ServiceAccount annotations for IRSA: {{ .Values.serviceAccount.annotations }}",
        "Add values.yaml defaults for config, secret, externalSecret, serviceAccount sections",
        "Verify `helm template` renders correctly with different value combinations"
      ],
      "priority": 17,
      "passes": false,
      "notes": "Configuration management - supports both direct secrets and ESO"
    },
    {
      "id": "US-018",
      "linearTicket": "SRE-45",
      "title": "Create KEDA ScaledObject and PDB Helm templates",
      "description": "As a DevOps engineer, I need Helm templates for KEDA-based autoscaling and availability.",
      "acceptanceCriteria": [
        "Create `helm/medic/templates/api-scaledobject.yaml` for KEDA",
        "ScaledObject creation controlled by {{ .Values.api.autoscaling.enabled }}",
        "ScaledObject targets medic-api deployment",
        "Min/max replicas configurable via values",
        "Configure CPU trigger with threshold from values",
        "Configure Prometheus trigger for custom metrics (e.g., request rate)",
        "Add cooldownPeriod and pollingInterval configuration",
        "Create `helm/medic/templates/worker-pdb.yaml` for PodDisruptionBudget",
        "PDB creation controlled by {{ .Values.worker.pdb.enabled }}",
        "Add Karpenter-friendly annotations for node scheduling (provisioner hints)",
        "Add topology spread constraints for multi-AZ distribution",
        "Add values.yaml defaults for autoscaling (keda) and pdb sections",
        "Verify `helm template` renders valid ScaledObject and PDB"
      ],
      "priority": 18,
      "passes": false,
      "notes": "Uses KEDA for scaling, Karpenter-aware scheduling"
    },
    {
      "id": "US-019",
      "linearTicket": "SRE-46",
      "title": "Implement OpenTelemetry instrumentation for tracing",
      "description": "As an operator, I need distributed tracing with OpenTelemetry for request correlation across services.",
      "acceptanceCriteria": [
        "Add `opentelemetry-api`, `opentelemetry-sdk`, `opentelemetry-instrumentation-flask` to requirements.txt",
        "Create `Medic/Core/telemetry.py` module for OTEL setup",
        "Configure TracerProvider with OTLP exporter (endpoint from env var)",
        "Auto-instrument Flask app with opentelemetry-instrumentation-flask",
        "Generate trace_id and span_id for each request",
        "Propagate W3C trace context headers",
        "Add `OTEL_EXPORTER_OTLP_ENDPOINT` env var (default: http://alloy:4317)",
        "Add `OTEL_SERVICE_NAME` env var (default: medic)",
        "Add `OTEL_RESOURCE_ATTRIBUTES` for environment, version labels",
        "Store current trace_id in Flask g context for log correlation",
        "Add unit tests for telemetry setup",
        "Typecheck/lint passes"
      ],
      "priority": 19,
      "passes": false,
      "notes": "OTEL tracing - Alloy collects via OTLP"
    },
    {
      "id": "US-020",
      "linearTicket": "SRE-47",
      "title": "Configure structured JSON logging with OTEL semantics",
      "description": "As an operator, I need structured JSON logs with OpenTelemetry semantic conventions and trace correlation for Grafana/Loki.",
      "acceptanceCriteria": [
        "Create `Medic/Core/logging_config.py` module",
        "Implement JSONFormatter with OTEL semantic conventions",
        "Include standard fields: timestamp, severity (OTEL level names), body (message)",
        "Include resource attributes: service.name, service.version, deployment.environment",
        "Include trace context: trace_id, span_id (from current OTEL context)",
        "Include request context: http.method, http.route, http.status_code",
        "Add `MEDIC_LOG_FORMAT` env var: 'json' (default) or 'text'",
        "Add `MEDIC_LOG_LEVEL` env var: DEBUG, INFO, WARNING, ERROR",
        "Integrate with telemetry.py to extract trace_id from current span",
        "Replace logger.log(level=20, msg=...) calls with standard methods",
        "Logs output to stdout for Alloy collection",
        "Add unit tests for JSONFormatter",
        "Typecheck/lint passes"
      ],
      "priority": 20,
      "passes": false,
      "notes": "OTEL semantic logging - trace_id enables Grafana log-to-trace correlation",
      "blockedBy": ["SRE-46"]
    },
    {
      "id": "US-021",
      "linearTicket": "SRE-48",
      "title": "Add OTEL metrics with exemplars for trace correlation",
      "description": "As an operator, I need Prometheus metrics with OTEL semantics and trace exemplars for Grafana metrics-to-trace correlation.",
      "acceptanceCriteria": [
        "Add `opentelemetry-instrumentation-prometheus` or use prometheus_client with exemplars",
        "Update `Medic/Core/metrics.py` to use OTEL metric naming conventions",
        "Add `medic_info` gauge with service.name, service.version, deployment.environment labels",
        "Configure histogram metrics to include trace_id exemplars",
        "Add exemplar support to request duration histogram",
        "Add exemplar support to playbook execution duration histogram",
        "Ensure metrics endpoint (/metrics) exposes exemplars in OpenMetrics format",
        "Add resource attributes as metric labels where appropriate",
        "Document available metrics with OTEL semantic names in `docs/metrics.md`",
        "Typecheck/lint passes"
      ],
      "priority": 21,
      "passes": false,
      "notes": "Exemplars enable Grafana to jump from metric spike to example trace",
      "blockedBy": ["SRE-46"]
    },
    {
      "id": "US-022",
      "linearTicket": "SRE-49",
      "title": "Create ServiceMonitor and PodMonitor Helm templates for Alloy",
      "description": "As an operator, I need ServiceMonitor for Alloy to discover and scrape Medic metrics.",
      "acceptanceCriteria": [
        "Create `helm/medic/templates/servicemonitor.yaml`",
        "ServiceMonitor creation controlled by {{ .Values.metrics.serviceMonitor.enabled }}",
        "Target medic-api service on /metrics endpoint",
        "Scrape interval configurable (default: 30s)",
        "Enable exemplar scraping with enableFeatures annotation if needed",
        "Add metric relabeling for OTEL resource attributes",
        "Add label: environment from {{ .Values.global.environment }}",
        "Create `helm/medic/templates/podmonitor.yaml` for worker if needed",
        "Add values.yaml defaults for metrics.serviceMonitor section",
        "Verify `helm template` renders valid ServiceMonitor"
      ],
      "priority": 22,
      "passes": false,
      "notes": "Alloy uses ServiceMonitor CRDs for metric discovery"
    },
    {
      "id": "US-023",
      "linearTicket": "SRE-50",
      "title": "Create Grafana dashboard ConfigMap with trace/log links",
      "description": "As an operator, I need a Grafana dashboard with drill-down links to traces and logs.",
      "acceptanceCriteria": [
        "Create `helm/medic/templates/grafana-dashboard.yaml` as ConfigMap",
        "Dashboard creation controlled by {{ .Values.grafana.dashboard.enabled }}",
        "ConfigMap has grafana_dashboard: '1' label for sidecar discovery",
        "Dashboard panels: request rate, error rate, latency p50/p95/p99 with exemplar display",
        "Dashboard panels: auth failures, rate limit hits, playbook executions",
        "Add data links from metrics panels to Tempo traces (using exemplar trace_id)",
        "Add data links from metrics panels to Loki logs (using time range and labels)",
        "Dashboard variables: environment, service, time range",
        "Configure Tempo and Loki datasource references",
        "Store dashboard JSON in `helm/medic/dashboards/medic-overview.json`",
        "Add values.yaml defaults for grafana section",
        "Verify dashboard JSON is valid"
      ],
      "priority": 23,
      "passes": false,
      "notes": "Full observability correlation: metrics -> traces -> logs"
    },
    {
      "id": "US-024",
      "linearTicket": "SRE-51",
      "title": "Create GitHub Actions workflow for build and test",
      "description": "As a DevOps engineer, I need automated builds and tests on push.",
      "acceptanceCriteria": [
        "Create `.github/workflows/build.yml`",
        "Trigger on: push to main, pull_request to main, workflow_dispatch",
        "Job: lint - runs ruff check and mypy",
        "Job: test - runs pytest with coverage, uploads coverage artifact",
        "Job: build - builds Docker image, tags with git SHA",
        "Job: helm-lint - runs helm lint on chart",
        "Cache pip dependencies using actions/cache",
        "Cache Docker layers using docker/build-push-action cache",
        "Jobs run in parallel where possible",
        "Verify workflow YAML is valid"
      ],
      "priority": 24,
      "passes": false,
      "notes": "CI pipeline"
    },
    {
      "id": "US-025",
      "linearTicket": "SRE-52",
      "title": "Create GitHub Actions workflow for multi-arch ECR push",
      "description": "As a DevOps engineer, I need Docker images built for both amd64 and arm64 and pushed to ECR.",
      "acceptanceCriteria": [
        "Extend `.github/workflows/build.yml` with push-ecr job",
        "Job runs only on push to main (not PRs): if: github.ref == 'refs/heads/main'",
        "Configure AWS credentials via OIDC using aws-actions/configure-aws-credentials",
        "Login to ECR using aws-actions/amazon-ecr-login",
        "Use docker/setup-qemu-action for cross-platform emulation",
        "Use docker/setup-buildx-action for multi-arch builds",
        "Build and push multi-arch manifest with: platforms: linux/amd64,linux/arm64",
        "Use docker/build-push-action with buildx",
        "Push image with tags: ${{ github.sha }}, latest (as manifest lists)",
        "Enable provenance and SBOM attestations",
        "Document required secrets: AWS_ROLE_ARN, AWS_REGION, ECR_REPOSITORY"
      ],
      "priority": 25,
      "passes": false,
      "notes": "Multi-arch build supports both x86 EC2/EKS and Graviton instances"
    },
    {
      "id": "US-026",
      "linearTicket": "SRE-53",
      "title": "Create GitHub Actions workflow for Terraform plan/apply",
      "description": "As a DevOps engineer, I need automated Terraform workflows for infrastructure and Helm deployment.",
      "acceptanceCriteria": [
        "Create `.github/workflows/terraform.yml`",
        "Trigger on: push to main (paths: terraform/**), pull_request (paths: terraform/**), workflow_dispatch",
        "Input: environment (dev/prod), action (plan/apply)",
        "Configure AWS credentials via OIDC",
        "Job: terraform-plan - runs terraform init, validate, plan",
        "Upload plan artifact for review",
        "Job: terraform-apply - runs terraform apply (requires approval for prod)",
        "Terraform applies both AWS infra AND Helm chart via helm_release resource",
        "Production environment requires manual approval",
        "Comment plan output on PRs using github-script",
        "Document required GitHub environments and secrets"
      ],
      "priority": 26,
      "passes": false,
      "notes": "Terraform deploys infra (RDS, Redis, Secrets) AND Helm chart via helm_release"
    },
    {
      "id": "US-027",
      "linearTicket": "SRE-54",
      "title": "Create Terraform module for RDS PostgreSQL",
      "description": "As a DevOps engineer, I need Terraform to provision RDS PostgreSQL.",
      "acceptanceCriteria": [
        "Create `terraform/` directory structure",
        "Create `terraform/modules/rds/main.tf` with aws_db_instance, aws_db_subnet_group, aws_security_group",
        "Create `terraform/modules/rds/variables.tf` with: instance_class, multi_az, vpc_id, subnet_ids, eks_security_group_id",
        "Create `terraform/modules/rds/outputs.tf` exposing: endpoint, port, database_name, connection_string",
        "PostgreSQL 15, storage 20GB gp3 with autoscaling to 100GB",
        "Security group allows inbound 5432 from EKS node security group only",
        "Automated backups: 7 days retention",
        "Create `terraform/.gitignore` for *.tfstate, .terraform/, *.tfvars",
        "Verify `terraform validate` passes in modules/rds"
      ],
      "priority": 27,
      "passes": false,
      "notes": "RDS outputs will be passed to Helm via helm_release"
    },
    {
      "id": "US-028",
      "linearTicket": "SRE-55",
      "title": "Create Terraform module for ElastiCache Redis",
      "description": "As a DevOps engineer, I need Terraform to provision ElastiCache Redis.",
      "acceptanceCriteria": [
        "Create `terraform/modules/elasticache/main.tf` with aws_elasticache_cluster, aws_elasticache_subnet_group, aws_security_group",
        "Create `terraform/modules/elasticache/variables.tf` with: node_type, vpc_id, subnet_ids, eks_security_group_id",
        "Create `terraform/modules/elasticache/outputs.tf` exposing: endpoint, port, connection_string",
        "Redis 7.x, single node (cluster_mode disabled)",
        "Security group allows inbound 6379 from EKS node security group only",
        "No snapshots (ephemeral rate limit data)",
        "Verify `terraform validate` passes in modules/elasticache"
      ],
      "priority": 28,
      "passes": false,
      "notes": "Redis outputs will be passed to Helm via helm_release"
    },
    {
      "id": "US-029",
      "linearTicket": "SRE-56",
      "title": "Create Terraform module for Secrets Manager and IAM",
      "description": "As a DevOps engineer, I need Terraform to manage Secrets Manager and IAM for ESO.",
      "acceptanceCriteria": [
        "Create `terraform/modules/secrets/main.tf` with aws_secretsmanager_secret",
        "Create `terraform/modules/secrets/variables.tf` with: environment, eks_oidc_provider_arn, eks_namespace",
        "Create `terraform/modules/secrets/outputs.tf` exposing: secret_arn, iam_role_arn",
        "Create secret: medic/${var.environment}/secrets",
        "Create IAM role with trust policy for EKS OIDC (for IRSA)",
        "Create IAM policy allowing secretsmanager:GetSecretValue, secretsmanager:DescribeSecret",
        "Attach policy to role",
        "Output IAM role ARN for ServiceAccount annotation",
        "Verify `terraform validate` passes in modules/secrets"
      ],
      "priority": 29,
      "passes": false,
      "notes": "IAM role ARN passed to Helm for ServiceAccount IRSA annotation"
    },
    {
      "id": "US-030",
      "linearTicket": "SRE-57",
      "title": "Create Terraform root module with helm_release for Medic",
      "description": "As a DevOps engineer, I need a root Terraform module that provisions AWS resources and deploys Helm chart.",
      "acceptanceCriteria": [
        "Create `terraform/environments/dev/main.tf` calling rds, elasticache, secrets modules",
        "Add helm provider configuration with EKS cluster authentication",
        "Add helm_release resource for medic chart",
        "Pass RDS endpoint to Helm values: set { name = 'config.DATABASE_URL', value = module.rds.connection_string }",
        "Pass Redis endpoint to Helm values",
        "Pass IAM role ARN for ServiceAccount annotation",
        "Pass environment-specific values (image tag, replicas, host)",
        "Create `terraform/environments/dev/variables.tf` with all required inputs",
        "Create `terraform/environments/dev/outputs.tf` with endpoints and URLs",
        "Create `terraform/environments/dev/backend.tf` for S3 state backend",
        "Create `terraform/environments/dev/terraform.tfvars.example`",
        "Data sources for existing VPC and EKS cluster",
        "Create `terraform/environments/prod/` with same structure (placeholder)",
        "Create `terraform/README.md` with usage instructions",
        "Verify `terraform init && terraform validate` passes"
      ],
      "priority": 30,
      "passes": false,
      "notes": "Single terraform apply provisions infra AND deploys app via Helm",
      "blockedBy": ["SRE-54", "SRE-55", "SRE-56"]
    },
    {
      "id": "US-031",
      "linearTicket": "SRE-58",
      "title": "Create database migration Helm hook job",
      "description": "As a DevOps engineer, I need database migrations to run automatically before Helm deployments.",
      "acceptanceCriteria": [
        "Create `helm/medic/templates/migration-job.yaml` as Kubernetes Job",
        "Use Helm hook: helm.sh/hook: pre-upgrade,pre-install",
        "Use Helm hook weight: helm.sh/hook-weight: '-5' (run before app)",
        "Use Helm hook delete policy: helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded",
        "Job runs migrations using same image as app",
        "Container command: ['python', '-m', 'scripts.run_migrations']",
        "Job uses same secrets and config as API deployment",
        "backoffLimit: 3",
        "Create `scripts/run_migrations.py` that applies migrations from migrations/ directory",
        "Job creation controlled by {{ .Values.migrations.enabled }}",
        "Add values.yaml defaults for migrations section",
        "Document migration workflow in README"
      ],
      "priority": 31,
      "passes": false,
      "notes": "Migrations run as Helm pre-upgrade hook"
    }
  ]
}
